{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b436c5a-ea6d-4c5c-bc27-8eb7052cdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# RAG System Performance Evaluation (Recall@K)\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Libraries\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "class NaturalQueryEvaluator:\n",
    "    def __init__(self, data_path, query_path):\n",
    "        self.data_path = data_path\n",
    "        self.query_path = query_path\n",
    "        \n",
    "        # Check device\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Device: {self.device.upper()}\")\n",
    "\n",
    "        # 1. Load Embedding Model\n",
    "        print(\"Loading embedding model (all-MiniLM-L6-v2)...\")\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            model_kwargs={'device': self.device}\n",
    "        )\n",
    "\n",
    "        # 2. Load Re-ranker Model\n",
    "        print(\"Loading re-ranker model (ms-marco-MiniLM-L-6-v2)...\")\n",
    "        self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=self.device)\n",
    "\n",
    "        self.doc_map = {}\n",
    "        self.docs_full = []\n",
    "        self.docs_meta = []\n",
    "\n",
    "    def _normalize(self, text):\n",
    "        return unicodedata.normalize('NFKD', str(text)).encode('ascii', 'ignore').decode('utf-8').lower().strip()\n",
    "\n",
    "    def load_and_preprocess(self):\n",
    "        print(\"Loading data...\")\n",
    "        if not os.path.exists(self.data_path):\n",
    "            raise FileNotFoundError(f\"Data file not found: {self.data_path}\")\n",
    "\n",
    "        loader = CSVLoader(self.data_path, encoding='utf-8', content_columns=['track_name', 'artist_name', 'lyrics', 'genre'])\n",
    "        self.docs_full = loader.load()\n",
    "\n",
    "        self.docs_meta = []\n",
    "        for i, doc in enumerate(self.docs_full):\n",
    "            doc.metadata['doc_id'] = i\n",
    "            lines = doc.page_content.split('\\n')\n",
    "            \n",
    "            try:\n",
    "                track_line = next((line for line in lines if \"track_name:\" in line), \"\")\n",
    "                artist_line = next((line for line in lines if \"artist_name:\" in line), \"\")\n",
    "\n",
    "                track = track_line.split(':', 1)[1].strip() if track_line else \"\"\n",
    "                artist = artist_line.split(':', 1)[1].strip() if artist_line else \"\"\n",
    "\n",
    "                key = (self._normalize(track), self._normalize(artist))\n",
    "                if track and artist:\n",
    "                    self.doc_map[key] = i\n",
    "            except: pass\n",
    "\n",
    "            # Create metadata-focused document for BM25\n",
    "            new_doc = copy.deepcopy(doc)\n",
    "            new_doc.page_content = self._normalize(\" \".join(lines[:3]))\n",
    "            new_doc.metadata['doc_id'] = i\n",
    "            self.docs_meta.append(new_doc)\n",
    "\n",
    "        print(f\"Data loaded: {len(self.docs_full)} documents\")\n",
    "\n",
    "    def build_engine(self):\n",
    "        print(\"Building hybrid search engine...\")\n",
    "\n",
    "        # 1. BM25\n",
    "        bm25 = BM25Retriever.from_documents(self.docs_meta)\n",
    "        bm25.k = 50\n",
    "\n",
    "        # 2. FAISS\n",
    "        vectorstore = FAISS.from_documents(self.docs_full, self.embeddings)\n",
    "        faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})\n",
    "\n",
    "        # 3. Ensemble\n",
    "        self.ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[bm25, faiss_retriever],\n",
    "            weights=[0.5, 0.5]\n",
    "        )\n",
    "\n",
    "    def run_evaluation(self, sample_size=1000):\n",
    "        print(f\"Starting evaluation (Target N={sample_size})...\")\n",
    "\n",
    "        if not os.path.exists(self.query_path):\n",
    "             raise FileNotFoundError(f\"Query file not found: {self.query_path}\")\n",
    "\n",
    "        df_queries = pd.read_csv(self.query_path)\n",
    "\n",
    "        if len(df_queries) > sample_size:\n",
    "            df_queries = df_queries.sample(sample_size, random_state=42)\n",
    "        else:\n",
    "            sample_size = len(df_queries)\n",
    "\n",
    "        k_values = [1, 3, 5, 10]\n",
    "        hits = {k: 0 for k in k_values}\n",
    "        total = 0\n",
    "\n",
    "        for _, row in tqdm(df_queries.iterrows(), total=len(df_queries), desc=\"Processing\"):\n",
    "            query = self._normalize(row['question'])\n",
    "\n",
    "            try:\n",
    "                true_track = self._normalize(row['ground_truth_track'])\n",
    "                true_artist = self._normalize(row['ground_truth_artist'])\n",
    "                ground_truth_id = self.doc_map.get((true_track, true_artist))\n",
    "                if ground_truth_id is None: continue \n",
    "            except: continue\n",
    "\n",
    "            total += 1\n",
    "\n",
    "            try:\n",
    "                # 1. Retrieval (Ensemble)\n",
    "                results = self.ensemble_retriever.invoke(query)\n",
    "\n",
    "                # 2. Re-ranking (Cross-Encoder)\n",
    "                pairs = [[query, doc.page_content] for doc in results]\n",
    "                \n",
    "                if pairs:\n",
    "                    scores = self.reranker.predict(pairs)\n",
    "                    scored_results = sorted(zip(results, scores), key=lambda x: x[1], reverse=True)\n",
    "                    reranked_docs = [doc for doc, score in scored_results]\n",
    "                else:\n",
    "                    reranked_docs = results\n",
    "\n",
    "                # Check hits\n",
    "                found_ids = [doc.metadata.get('doc_id') for doc in reranked_docs]\n",
    "\n",
    "                for k in k_values:\n",
    "                    if ground_truth_id in found_ids[:k]:\n",
    "                        hits[k] += 1\n",
    "            except: continue\n",
    "\n",
    "        # Report\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Final Report: {total} samples evaluated\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        recall_scores = []\n",
    "        for k in k_values:\n",
    "            score = (hits[k] / total) * 100 if total > 0 else 0\n",
    "            recall_scores.append(score)\n",
    "            print(f\"Recall@{k:<2} : {score:.2f}%\")\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(k_values, recall_scores, 'b*-', linewidth=2, markersize=10, label='Re-ranker (Final)')\n",
    "        plt.title(f'RAG Performance on {total} Queries', fontsize=16)\n",
    "        plt.xlabel('Top-K', fontsize=12)\n",
    "        plt.ylabel('Recall (%)', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.ylim(0, 105)\n",
    "        plt.xticks(k_values)\n",
    "        for x, y in zip(k_values, recall_scores):\n",
    "            plt.text(x, y+3, f\"{y:.1f}%\", ha='center', fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    DATA_FILE = \"final_preprocessed_music_data.csv\"\n",
    "    QUERY_FILE = \"generated_query_set_1000_llm.csv\"\n",
    "\n",
    "    print(f\"Data path: {os.path.abspath(DATA_FILE)}\")\n",
    "    print(f\"Query path: {os.path.abspath(QUERY_FILE)}\")\n",
    "\n",
    "    if os.path.exists(DATA_FILE) and os.path.exists(QUERY_FILE):\n",
    "        evaluator = NaturalQueryEvaluator(DATA_FILE, QUERY_FILE)\n",
    "        evaluator.load_and_preprocess()\n",
    "        evaluator.build_engine()\n",
    "        evaluator.run_evaluation(sample_size=1000)\n",
    "    else:\n",
    "        print(\"Error: Input files not found. Please check the file paths.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (rag2026)",
   "language": "python",
   "name": "rag2026"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
